{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okt5jAa0Qdgp"
      },
      "source": [
        "# Signatures verification using SiameseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxPRPi8wfpQB"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary Library \n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn \n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL.ImageOps    \n",
        "from PIL import Image\n",
        "import urllib #<! Download internet files\n",
        "import shutil #<! Handle zip files\n",
        "import itertools\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "\n",
        "!pip install torchinfo #<! display model summary\n",
        "from torchinfo import summary\n",
        "\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfm29eeogy7D"
      },
      "outputs": [],
      "source": [
        "# check if GPU device is active\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "  print('Deivece is: GPU')\n",
        "else:\n",
        "  print('Deivece is: CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8u6_4Cy_JCe"
      },
      "outputs": [],
      "source": [
        "# connect to google drive to save dataset and models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvNjsKNbFaA1"
      },
      "outputs": [],
      "source": [
        "# load tensorboard and import summery writer \n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKT0Q4meytM9"
      },
      "source": [
        "## The Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbo3OFLHdujL"
      },
      "source": [
        "### Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rblM0eaf2oL"
      },
      "outputs": [],
      "source": [
        "# Login Into Kaggle\n",
        "# See https://www.kaggle.com/general/74235\n",
        "# See https://gist.github.com/jayspeidell/d10b84b8d3da52df723beacc5b15cb27\n",
        "# The JSON file content:\n",
        "# {\"username\":\"fixelalgorithms\",\"key\":\"53fb9c2e60051daa41be41cd5c9c8456\"}\n",
        "\n",
        "# read kaggel credentails from text file\n",
        "f = open('/content/drive/MyDrive/siameseNetwork/Kaggel.txt', 'r')\n",
        "lines = f.readlines()\n",
        "username = lines[0].strip()\n",
        "token = lines[1].strip()\n",
        "f.close()\n",
        "\n",
        "name = os.environ['KAGGLE_USERNAME'] = username\n",
        "test = os.environ['KAGGLE_KEY'] = token\n",
        "\n",
        "# !kaggle datasets download -d iarunava/happy-house-dataset #<! Download Kaggle Data Set\n",
        "userName    = 'robinreni'\n",
        "dataSetName = 'signature-verification-dataset'\n",
        "!kaggle datasets download -d $userName/$dataSetName #<! Download Kaggle Data Set ($ for string interpolation)\n",
        "shutil.unpack_archive(f'{dataSetName}.zip', './DataSet') #<! Unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tbSAK64eD1E"
      },
      "source": [
        "### Dataset Preprocessing and Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7BcbB-4nX3t"
      },
      "outputs": [],
      "source": [
        "# create new train csv file containing only classes between 001-048, as original train file holds all the 69 signatures classes \n",
        "df_train = pd.read_csv('/content/DataSet/sign_data/train_data.csv', names=[\"image1\",\"image2\",\"label\"], encoding = \"UTF-8\")\n",
        "df_train_new = df_train[df_train['image1'].str[:3].astype(int)<49].sort_values('image1') # extract first 3 charecters, convert to int and filter the dataset\n",
        "df_train_new.to_csv('/content/DataSet/sign_data/train_data_new.csv', header=False, index=False, encoding = \"UTF-8\")\n",
        "\n",
        "# create sample data for testing model\n",
        "train_sample = df_train_new.iloc[:10000,]\n",
        "train_sample.to_csv('/content/DataSet/sign_data/train_sample.csv', header=False, index=False, encoding = \"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2x3N0wifzHi"
      },
      "outputs": [],
      "source": [
        "# check contenet of dataset library\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../content/DataSet/sign_data\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayg1yr-LgV4c"
      },
      "source": [
        "* Define paths for training and testing datasets and csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dYAZPKWgcGv"
      },
      "outputs": [],
      "source": [
        "training_dir=\"../content/DataSet/sign_data/train\"\n",
        "training_csv=\"../content/DataSet/sign_data/train_sample.csv\"\n",
        "testing_csv=\"../content/DataSet/sign_data/test_data.csv\"\n",
        "testing_dir=\"../content/DataSet/sign_data/test\"\n",
        "real_dir='/content/drive/MyDrive/siameseNetwork/signatures'\n",
        "real_csv='/content/drive/MyDrive/siameseNetwork/signatures/real_data.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ9yMmh1g8LV"
      },
      "source": [
        "* Create Dataset class to generate a pair of images with label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRmEsI6mgwqZ"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset():\n",
        "    \n",
        "    def __init__(self, training_csv=None, training_dir=None, transform=None, device=device):\n",
        "        # used to prepare the labels and images path\n",
        "        self.training_df= pd.read_csv(training_csv, names=[\"image1\",\"image2\",\"label\"])\n",
        "        self.training_dir = training_dir    \n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self,index):   \n",
        "        # getting the image path\n",
        "        image1_path=os.path.join(self.training_dir, self.training_df.iat[index, 0])\n",
        "        image2_path=os.path.join(self.training_dir, self.training_df.iat[index, 1])\n",
        "        \n",
        "        # Loading images\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\") # Convert to one chanel (gray scale)\n",
        "        img1 = img1.convert(\"L\")\n",
        "        \n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        label = torch.from_numpy(np.array([int(self.training_df.iat[index, 2])], dtype=np.float32))\n",
        "        label = label[0]\n",
        "        return img0, img1, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.training_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SAdieTNtGX2"
      },
      "source": [
        "### Load and Batch the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_AwUhflgTlT"
      },
      "outputs": [],
      "source": [
        "class Config():\n",
        "    train_batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hCZ7WGe_Abt"
      },
      "outputs": [],
      "source": [
        "# choose a training dataset size and further divide it into train and validation set\n",
        "\n",
        "# Load the dataset from raw image folders\n",
        "siamese_dataset = SiameseNetworkDataset(training_csv, training_dir, transform=None)\n",
        "\n",
        "# Load a second dataset to be used for splitting data to train and val sets with different image transformers\n",
        "train_dataset = SiameseNetworkDataset(training_csv, training_dir)\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, val_indices, _, _ = train_test_split(\n",
        "                                                    range(len(train_dataset)),\n",
        "                                                    train_dataset.training_df.label,\n",
        "                                                    test_size=0.1,\n",
        "                                                    random_state=42,\n",
        "                                                    shuffle=False\n",
        "                                                    )\n",
        "# generate subset based on indices\n",
        "train_set = Subset(train_dataset, train_indices)\n",
        "val_set = Subset(siamese_dataset, val_indices)\n",
        "\n",
        "# define different image transformers for train and val sets\n",
        "train_set.dataset.transform  = transforms.Compose([\n",
        "                                                  transforms.RandomRotation((-3,3), fill=0, expand=True),\n",
        "                                                  transforms.Resize((128,128)),\n",
        "                                                  transforms.ToTensor()\n",
        "                                                  ])\n",
        "val_set.dataset.transform  = transforms.Compose([\n",
        "                                                transforms.Resize((128,128)),\n",
        "                                                transforms.ToTensor()\n",
        "                                                ])\n",
        "test_dataset = SiameseNetworkDataset(training_csv=testing_csv, training_dir=testing_dir,\n",
        "                                    transform=transforms.Compose([transforms.Resize((128,128)),\n",
        "                                                                  transforms.ToTensor()\n",
        "                                                                  ])\n",
        "                                    )\n",
        "# load training data in batches\n",
        "train_dataloader = DataLoader(train_set,\n",
        "                              shuffle=True,\n",
        "                              num_workers=2,\n",
        "                              batch_size= Config.train_batch_size)\n",
        "# load validation data in batches\n",
        "val_dataloader = DataLoader(val_set,\n",
        "                            shuffle=True,\n",
        "                            num_workers=2,\n",
        "                            batch_size= Config.train_batch_size)\n",
        "# load test data in batches\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                             num_workers=2,\n",
        "                             batch_size=1,\n",
        "                             shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcin-BkUwiNP"
      },
      "source": [
        "* Small dataset of real personal signatures samples for testing model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGue0r53j4o9"
      },
      "outputs": [],
      "source": [
        "# dataset of real signatures samples for testing model result\n",
        "real_dataset = SiameseNetworkDataset(training_csv=real_csv, training_dir=real_dir,\n",
        "                                    transform=transforms.Compose([transforms.Resize((128,128)),\n",
        "                                                                  transforms.ToTensor()\n",
        "                                                                ])\n",
        "                                    )\n",
        "# load real dataset for testing\n",
        "real_dataloader = DataLoader(real_dataset,\n",
        "                              shuffle=True,\n",
        "                              num_workers=2,\n",
        "                              batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTGNbDc3fuop"
      },
      "outputs": [],
      "source": [
        "# A helper function to plot images\n",
        "def imshow(img, text=None, should_save=False, aspect='auto'):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text ,fontsize=12, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfv4GlWjhPpG"
      },
      "outputs": [],
      "source": [
        "# View sample of images and check whether its loading properly\n",
        "vis_dataloader = DataLoader(val_set, shuffle=True, batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "plt.figure(figsize=[15, 15])\n",
        "example_batch = next(dataiter)\n",
        "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6poP03Ty1in"
      },
      "source": [
        "## Deep learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJskzJY9ZMYn"
      },
      "source": [
        "### SiameseNet\n",
        "Net architecture (Based on CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAEtNAzQITCm"
      },
      "outputs": [],
      "source": [
        "#create a siamese network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout2d(p=.2),\n",
        "\n",
        "            nn.Conv2d(4, 8, kernel_size=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout2d(p=.4),\n",
        "\n",
        "            nn.Conv2d(8, 8, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout2d(p=.2),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(8*14*14, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(500, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=.3),\n",
        "            nn.Linear(128, 16)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q33H2JukJ32"
      },
      "source": [
        "#### Checkpoints:\n",
        "A checkpoints mechanisim enabeling to save and load model with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWcIV7HFulZL"
      },
      "outputs": [],
      "source": [
        "# saving and loading checkpoint mechanisms\n",
        "\n",
        "def save_checkpoint(save_path, model, optimizer, val_loss, epoch):\n",
        "    if save_path==None:\n",
        "      return\n",
        "    save_path = save_path \n",
        "    state_dict = {'epoch': epoch+1,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_loss': val_loss}\n",
        "    torch.save(state_dict, save_path)   \n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'/content/drive/MyDrive/siameseNetwork/siameseNet.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    epoch = state_dict['epoch']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "        \n",
        "    return model, optimizer, epoch, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhBEt_u9JaGf"
      },
      "source": [
        "#### Loss functions:\n",
        "Two loss fucntion were tested in this model: ContrastiveLoss and BCEWithLotgitsLoss. At the end I used the BCEWithLotgitsLoss function since it gave better results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1tk9JB0mot6"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "  def __init__(self, margin=2.0):\n",
        "    super(ContrastiveLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def forward(self, output1, output2, label):\n",
        "    #label should be one dimensional!!!\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "    loss = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "    return loss\n",
        "\n",
        "class MyBCELoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyBCELoss, self).__init__()\n",
        "    self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def forward(self, output1, output2, label):\n",
        "    output = torch.max(abs(output1 - output2),1)[0]\n",
        "    # output = (output1 * output2).sum(axis=1)\n",
        "    return self.loss_fn(output, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-wRcE74oxsC"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader, num_epochs, criterion, save_name):\n",
        "    best_val_loss = float(\"Inf\") \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracy = []\n",
        "    y_predicted = []\n",
        "    y_target = []\n",
        " \n",
        "    for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      model.train()\n",
        "      print(\"Starting epoch \" + str(epoch+1))\n",
        "      for i, data in enumerate(train_dataloader,0):\n",
        "          img0, img1, label = data\n",
        "          img0, img1, label = img0.to(device), img1.to(device) , label.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output1, output2 = net(img0, img1)\n",
        "          output = torch.max(abs(output1 - output2),1)[0] #>! disable when using ContrastiveLoss function\n",
        "          loss = criterion(output, label)\n",
        "          # loss = criterion(output1 ,output2, label) #>! enable when using ContrastiveLoss function and disable above line\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "      avg_train_loss = running_loss / len(train_dataloader)\n",
        "      train_losses.append(avg_train_loss)\n",
        "\n",
        "      #check validation loss after every epoch      \n",
        "      val_running_acc = 0.0\n",
        "      val_running_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for img0, img1, label in val_dataloader:\n",
        "            img0, img1, label = img0.to(device), img1.to(device) , label.to(device)\n",
        "            output1, output2 = net(img0, img1)\n",
        "            output = torch.max(abs(output1 - output2),1)[0] #>! disable when using ContrastiveLoss function\n",
        "            loss = criterion(output, label)\n",
        "            # loss = criterion(output1 ,output2, label) #>! enable when using ContrastiveLoss function and disable above line\n",
        "            val_running_loss += loss.item()\n",
        "            result = torch.abs(output1 - output2)\n",
        "            result = torch.max(result, 1)[0]\n",
        "            y_pred = (result > 0.1)\n",
        "            val_running_acc += torch.sum(y_pred == label.data)\n",
        "        \n",
        "      avg_val_loss = val_running_loss/len(val_dataloader)\n",
        "      val_losses.append(avg_val_loss)\n",
        "      avg_val_acc = val_running_acc/len(val_set)\n",
        "      val_accuracy.append(avg_val_acc)\n",
        "      print('Epoch [{}/{}]... Train Loss:{:.4f}... Valid Loss:{:.4f}... Val Accuracy:{:.4f}'\n",
        "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss, avg_val_acc))\n",
        "      \n",
        "      # save model with best evaluation loss\n",
        "      if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        save_checkpoint(save_name, model, optimizer, best_val_loss, epoch+1)\n",
        "\n",
        "      # write various tracked parameters to Tensorboard\n",
        "      writer.add_graph(net, input_to_model=[img0, img1])\n",
        "      writer.add_scalar('epoch training loss', avg_train_loss, epoch+1)\n",
        "      writer.add_scalar('epoch Val loss', avg_val_loss, epoch+1)\n",
        "      writer.add_scalar('epoch Val Accuracy', avg_val_acc, epoch+1)\n",
        "      writer.close()\n",
        "\n",
        "    print(\"Finished Training\")  \n",
        "    return train_losses, val_losses, val_accuracy  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrV9NAlKj9VL"
      },
      "source": [
        "### Train the model\n",
        "* You have the option to load a saved model and retrain it. In this case, markout the 'net = Net().to(device)' at the top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgAa3tnElWDy"
      },
      "outputs": [],
      "source": [
        "# actual training\n",
        "net = Net().to(device)\n",
        "num_epochs = 50\n",
        "lr = 0.00004\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "# criterion = ContrastiveLoss()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "save_path = '/content/drive/MyDrive/siameseNetwork/siameseNet.pt'\n",
        "\n",
        "# Loading saved model for retrain\n",
        "# net, optimizer, epoch, val_loss = load_checkpoint(net, optimizer)\n",
        "\n",
        "# define Tensorboard writer configuration\n",
        "comment = f'batch_size = {Config.train_batch_size} lr = {lr}'\n",
        "log_folder = '/content/drive/MyDrive/siameseNetwork/runs/' +'siam_70 -' + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\") +  comment\n",
        "writer = SummaryWriter(log_dir=log_folder, flush_secs=1)\n",
        "\n",
        "train_losses, val_losses, val_accuracy = train(net, train_dataloader, val_dataloader, num_epochs, criterion, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68giW6QOzjR7"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PLxeBfrEyux"
      },
      "outputs": [],
      "source": [
        "#!kill $(ps aux | awk '{print $2}') # kill tensorboard session <#! code used to forcefully terminate tensorboard session in colab when it fails to load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIveD_B_rYj1"
      },
      "outputs": [],
      "source": [
        "tensorboard  --logdir='/content/drive/MyDrive/siameseNetwork/runs/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrhs0xRcywxY"
      },
      "source": [
        "### Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQjSJ0Evn1ck"
      },
      "outputs": [],
      "source": [
        "# Net layout and parameters\n",
        "net = Net()\n",
        "summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zge9Jt5wSXv"
      },
      "outputs": [],
      "source": [
        "# view best saved model parameters\n",
        "load_model = Net().to(device)\n",
        "load_optimizer = optim.Adam(load_model.parameters(), lr=0.005)\n",
        "best_model = load_checkpoint(load_model, load_optimizer)\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrrQbBhNtSQP"
      },
      "outputs": [],
      "source": [
        "# plotting of training and validation loss\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
        "plt.figure(figsize=(15,15)).show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKD7D0tbimOW"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMvwRmTu8aN"
      },
      "source": [
        "### Test Trained Network Accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_On9oS0xsu",
        "outputId": "9bbbba6a-2d37-412e-bb19-c7c566919bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 5321/5748 (92.6%)\n"
          ]
        }
      ],
      "source": [
        "# Disable grad\n",
        "with torch.no_grad():\n",
        "  # Loading the saved model\n",
        "  save_path = f'/content/drive/MyDrive/siameseNetwork/siameseNet.pt'\n",
        "  net = Net().to(device)\n",
        "  checkpoint = torch.load(save_path)\n",
        "  net.load_state_dict(checkpoint['model_state_dict']) \n",
        "  net.eval()\n",
        "\n",
        "accuracy=0\n",
        "correct=0\n",
        "for i, data in enumerate(test_dataloader, 0): \n",
        "  x0, x1, label = data\n",
        "  # onehsot applies in the output of 128 dense vectors which is then converted to 16 dense vectors\n",
        "  output1, output2 = net(x0.to(device), x1.to(device))\n",
        "  result = torch.abs(output1.to(device) - output2.to(device))\n",
        "  result = torch.max(result, 1)[0]\n",
        "  result = torch.sigmoid(result).data.cpu().numpy()\n",
        "  label = label.data.cpu().numpy()\n",
        "  y_pred = 1 if result > 0.5 else 0\n",
        "  correct += 1 if y_pred == label else 0\n",
        "\n",
        "accuracy = (correct/len(test_dataloader))*100\n",
        "print(\"Accuracy: {}/{} ({:.3}%)\".format(correct, len(test_dataloader), accuracy)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su1nH1uPwSET"
      },
      "source": [
        "### Visualize Signatures Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdzrLPDUMUAO"
      },
      "outputs": [],
      "source": [
        "# Print the sample outputs to view its dissimilarity\n",
        "counter=0\n",
        "list_0 = torch.FloatTensor([0])\n",
        "list_1 = torch.FloatTensor([1])\n",
        "\n",
        "# Loading the saved model\n",
        "save_path = f'/content/drive/MyDrive/siameseNetwork/siameseNet.pt'\n",
        "net = Net().to(device)\n",
        "checkpoint = torch.load(save_path)\n",
        "net.load_state_dict(checkpoint['model_state_dict']) \n",
        "\n",
        "for i, data in enumerate(test_dataloader, 0): \n",
        "  x0, x1, label = data\n",
        "  concatenated = torch.cat((x0,x1),0)\n",
        "  output1, output2 = net(x0.to(device), x1.to(device))\n",
        "  result = torch.abs(output1.to(device) - output2.to(device))\n",
        "  result = torch.max(result, 1)[0]\n",
        "  result = torch.sigmoid(result).data.cpu().numpy()[0]\n",
        "  label = label.data.cpu().numpy()[0]\n",
        "  if label==list_0:\n",
        "    label=\"Original\"\n",
        "  else:\n",
        "    label=\"Forged\"\n",
        "    \n",
        "  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f} Label: {}'.format(result, label))\n",
        "  counter=counter+1\n",
        "  if counter ==20:\n",
        "     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZMLdYYOfxg"
      },
      "source": [
        "### Test - Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaKKobJR5D3T"
      },
      "outputs": [],
      "source": [
        "# Disable grad\n",
        "with torch.no_grad():\n",
        "  # Loading the saved model\n",
        "  save_path = f'/content/drive/MyDrive/siameseNetwork/siameseNet.pt'\n",
        "  net = Net().to(device)\n",
        "  checkpoint = torch.load(save_path)\n",
        "  net.load_state_dict(checkpoint['model_state_dict']) \n",
        "  net.eval()\n",
        "\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "\n",
        "  # iterate over test data\n",
        "  for i, data in enumerate(test_dataloader, 0):\n",
        "    x0, x1, label = data\n",
        "    output1, output2 = net(x0.to(device), x1.to(device))\n",
        "    result = torch.abs(output1.to(device) - output2.to(device))\n",
        "    result = torch.max(result, 1)[0]\n",
        "    result = torch.sigmoid(result).data.cpu().numpy()\n",
        "    label = label.data.cpu().numpy()\n",
        "    result = [1 if result > 0.5 else 0]\n",
        "    y_pred.extend(result) # predictions\n",
        "    y_true.extend(label) # ground true\n",
        "\n",
        "  # constant for classes\n",
        "  classes = ('Original', 'Forged')\n",
        "\n",
        "  # Build confusion matrix\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes],\n",
        "                      columns = [i for i in classes])\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sn.set(font_scale=1.4)\n",
        "  ax = sn.heatmap(df_cm, annot=True, fmt='.1%',square=1, linewidth=1.)\n",
        "  cbar = ax.collections[0].colorbar\n",
        "  cbar.set_ticks([0.1, 0.2, 0.3, 0.4])\n",
        "  cbar.set_ticklabels(['10%', '20%', '30%', '40%'])\n",
        "  plt.savefig('output.png')\n",
        "  print(f'Confusion matrix:\\n {cf_matrix}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "signatures_verification_siameseNet (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}